<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Bridge : you &amp; me  | 基本特征选择方法</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.57.2" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    

    <meta property="og:title" content="基本特征选择方法" />
<meta property="og:description" content="其中data为特征的DataFrame，y为目标值的Series，y_pre为预测值的Series
Filter 基于统计量的预处理  缺失值比例删除：删除高缺失值的特征（列）
percent = data.isnull().sum() / len(data) * 100 result = data.loc[percent &lt; 50]  方差值删除：删除低方差的特征（列）
var = data.var() result = data.loc[var &gt; 0.1]  相关性矩阵：首先计算出特征之间的相关性，然后根据相关性的大小排序，按顺序删除冗余的特征
# 将数值范围变化到0-1之间 data = data.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))) # 相关性矩阵 cor = data.corr() # 按相关性大小逐步剔除 drop_pairs = [] for i in range(len(cor.index)): for j in range(len(cor.columns)): if cor.iloc[i,j] &gt;= 0.8 and i != j: drop_pairs.append([cor.index[i], cor." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://horizonnn.github.io/post/%E5%9F%BA%E6%9C%AC%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%96%B9%E6%B3%95/" />
<meta property="article:published_time" content="2020-09-26T11:08:40+08:00" />
<meta property="article:modified_time" content="2020-09-26T11:08:40+08:00" />
<meta itemprop="name" content="基本特征选择方法">
<meta itemprop="description" content="其中data为特征的DataFrame，y为目标值的Series，y_pre为预测值的Series
Filter 基于统计量的预处理  缺失值比例删除：删除高缺失值的特征（列）
percent = data.isnull().sum() / len(data) * 100 result = data.loc[percent &lt; 50]  方差值删除：删除低方差的特征（列）
var = data.var() result = data.loc[var &gt; 0.1]  相关性矩阵：首先计算出特征之间的相关性，然后根据相关性的大小排序，按顺序删除冗余的特征
# 将数值范围变化到0-1之间 data = data.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))) # 相关性矩阵 cor = data.corr() # 按相关性大小逐步剔除 drop_pairs = [] for i in range(len(cor.index)): for j in range(len(cor.columns)): if cor.iloc[i,j] &gt;= 0.8 and i != j: drop_pairs.append([cor.index[i], cor.">


<meta itemprop="datePublished" content="2020-09-26T11:08:40&#43;08:00" />
<meta itemprop="dateModified" content="2020-09-26T11:08:40&#43;08:00" />
<meta itemprop="wordCount" content="200">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="基本特征选择方法"/>
<meta name="twitter:description" content="其中data为特征的DataFrame，y为目标值的Series，y_pre为预测值的Series
Filter 基于统计量的预处理  缺失值比例删除：删除高缺失值的特征（列）
percent = data.isnull().sum() / len(data) * 100 result = data.loc[percent &lt; 50]  方差值删除：删除低方差的特征（列）
var = data.var() result = data.loc[var &gt; 0.1]  相关性矩阵：首先计算出特征之间的相关性，然后根据相关性的大小排序，按顺序删除冗余的特征
# 将数值范围变化到0-1之间 data = data.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))) # 相关性矩阵 cor = data.corr() # 按相关性大小逐步剔除 drop_pairs = [] for i in range(len(cor.index)): for j in range(len(cor.columns)): if cor.iloc[i,j] &gt;= 0.8 and i != j: drop_pairs.append([cor.index[i], cor."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://horizonnn.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">
      Bridge : you &amp; me
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/post/" title="Posts page">
              Posts
            </a>
          </li>
          
        </ul>
      
      











    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        POSTS
      </p>
      <h1 class="f1 athelas mb1">基本特征选择方法</h1>
      
      <time class="f6 mv4 dib tracked" datetime="2020-09-26T11:08:40&#43;08:00">September 26, 2020</time>
      
      
    </header>

    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l">

<p>其中data为特征的DataFrame，y为目标值的Series，y_pre为预测值的Series</p>

<h1 id="filter">Filter</h1>

<h3 id="基于统计量的预处理">基于统计量的预处理</h3>

<ul>
<li><p>缺失值比例删除：删除高缺失值的特征（列）</p>

<pre><code>percent = data.isnull().sum() / len(data) * 100
result = data.loc[percent &lt; 50]
</code></pre></li>

<li><p>方差值删除：删除低方差的特征（列）</p>

<pre><code>var = data.var()
result = data.loc[var &gt; 0.1]
</code></pre></li>

<li><p>相关性矩阵：首先计算出特征之间的相关性，然后根据相关性的大小排序，按顺序删除冗余的特征</p>

<pre><code class="language-python"># 将数值范围变化到0-1之间
data = data.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))
# 相关性矩阵
cor = data.corr()
# 按相关性大小逐步剔除
drop_pairs = []
for i in range(len(cor.index)):
  for j in range(len(cor.columns)):
      if cor.iloc[i,j] &gt;= 0.8 and i != j:
          drop_pairs.append([cor.index[i], cor.columns[j], cor.iloc[i,j]])
  
drop_pairs.sort(key=lambda x:x[2], reverse=True)
  
data_corr_mean = 0.6
drop_cols = []
for pair in drop_pairs:
  if pair[0] in drop_cols or pair[1] in drop_cols:
      continue
  else:
      drop_cols.append(pair[0] if data_corr_mean[pair[0]] &gt; data_corr_mean[pair[1]] else pair[1])
indices = set([x for x in data.columns if x not in drop_cols])
return data[indices]
</code></pre></li>
</ul>

<h3 id="基于统计量的排序">基于统计量的排序</h3>

<ul>
<li>分类问题：卡方检验、f_classif、mutual_info_classif、互信息</li>
<li>回归问题：皮尔森相关系数、f_regression、mutual_info_regression、最大信息系数</li>
</ul>

<h5 id="f-regression">f regression</h5>

<p>f regression的公式是$f = \frac{(x-\bar{x})(y-\bar{y})}{std(x)std(y)}$，其实就是在计算Pearson相关系数。但缺点在于只对线性关系敏感，对非线性关系并不敏感</p>

<pre><code class="language-python">from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression

# 选取分数最高的10个特征
selector = SelectKBest(f_regression, k=10).fit(data, y)
indices = data.columns[selector.get_support()]
return data[indices]
</code></pre>

<h1 id="wrapper">Wrapper</h1>

<h3 id="正向特征消除">正向特征消除</h3>

<h3 id="反向特征消除">反向特征消除</h3>

<h3 id="递归特征消除-rfe">递归特征消除（RFE）</h3>

<pre><code class="language-python">from sklearn.feature_selection import RFE
def RFE_select(estimator, select_num, data, y)
    elselector = RFE(estimator, n_features_to_select=select_num)
    selector = sector.fit(data, y)
    indices = set(features.columns[selector.support_])
    return data[indices]
</code></pre>

<h1 id="embedded">Embedded</h1>

<h3 id="基于正则化的特征选择">基于正则化的特征选择</h3>

<h5 id="lasso-l1正则化">LASSO（L1正则化）</h5>

<h5 id="ridge-l2正则化">Ridge（L2正则化）</h5>

<h3 id="随机稀疏模型">随机稀疏模型</h3>

<h3 id="基于树的特征选择">基于树的特征选择</h3>

<h5 id="随机森林">随机森林</h5>

<p>根据随机森林中得到的特征重要性进行排序得出特征的优先级</p>

<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor()
model.fit(data, y)

# 选取最重要的前10个特征
indices = np.argsort(model.feature_importances_)[0:10]
return data[indices]
</code></pre>

<h1 id="特征提取">特征提取</h1>

<h3 id="因子分析-fa">因子分析（FA）</h3>

<h3 id="独立分量分析-ica">独立分量分析（ICA）</h3>

<h1 id="线性特征组合">线性特征组合</h1>

<h3 id="主成分分析-pca">主成分分析（PCA）</h3>

<h1 id="非线性特征组合">非线性特征组合</h1>

<h3 id="isomap">ISOMAP</h3>

<h3 id="tsne">TSNE</h3>

<h3 id="umap">UMAP</h3>
<ul class="pa0">
  
</ul>
<div class="mt6">
      
      
      </div>
    </section>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://horizonnn.github.io/" >
    &copy; 2020 Bridge : you &amp; me
  </a>
    <div>










</div>
  </div>
</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
