<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Bridge : you &amp; me  | 基本特征选择方法</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.75.1" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    

    <meta property="og:title" content="基本特征选择方法" />
<meta property="og:description" content="其中data为特征的DataFrame，y为目标值的Series，y_pre为预测值的Series
Filter 基于统计量的预处理   缺失值比例删除：删除高缺失值的特征（列）
percent = data.isnull().sum() / len(data) * 100 result = data.loc[percent &lt; 50]   方差值删除：删除低方差的特征（列）
var = data.var() result = data.loc[var &gt; 0.1]   相关性矩阵：首先计算出特征之间的相关性，然后根据相关性的大小排序，按顺序删除冗余的特征
# 将数值范围变化到0-1之间 data = data.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))) # 相关性矩阵 cor = data.corr() # 按相关性大小逐步剔除 drop_pairs = [] for i in range(len(cor.index)): for j in range(len(cor.columns)): if cor.iloc[i,j] &gt;= 0.8 and i != j: drop_pairs." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://horizonnn.github.io/post/%E5%9F%BA%E6%9C%AC%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%96%B9%E6%B3%95/" />
<meta property="article:published_time" content="2020-09-26T11:08:40+08:00" />
<meta property="article:modified_time" content="2020-09-26T11:08:40+08:00" />
<meta itemprop="name" content="基本特征选择方法">
<meta itemprop="description" content="其中data为特征的DataFrame，y为目标值的Series，y_pre为预测值的Series
Filter 基于统计量的预处理   缺失值比例删除：删除高缺失值的特征（列）
percent = data.isnull().sum() / len(data) * 100 result = data.loc[percent &lt; 50]   方差值删除：删除低方差的特征（列）
var = data.var() result = data.loc[var &gt; 0.1]   相关性矩阵：首先计算出特征之间的相关性，然后根据相关性的大小排序，按顺序删除冗余的特征
# 将数值范围变化到0-1之间 data = data.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))) # 相关性矩阵 cor = data.corr() # 按相关性大小逐步剔除 drop_pairs = [] for i in range(len(cor.index)): for j in range(len(cor.columns)): if cor.iloc[i,j] &gt;= 0.8 and i != j: drop_pairs.">
<meta itemprop="datePublished" content="2020-09-26T11:08:40+08:00" />
<meta itemprop="dateModified" content="2020-09-26T11:08:40+08:00" />
<meta itemprop="wordCount" content="200">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="基本特征选择方法"/>
<meta name="twitter:description" content="其中data为特征的DataFrame，y为目标值的Series，y_pre为预测值的Series
Filter 基于统计量的预处理   缺失值比例删除：删除高缺失值的特征（列）
percent = data.isnull().sum() / len(data) * 100 result = data.loc[percent &lt; 50]   方差值删除：删除低方差的特征（列）
var = data.var() result = data.loc[var &gt; 0.1]   相关性矩阵：首先计算出特征之间的相关性，然后根据相关性的大小排序，按顺序删除冗余的特征
# 将数值范围变化到0-1之间 data = data.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))) # 相关性矩阵 cor = data.corr() # 按相关性大小逐步剔除 drop_pairs = [] for i in range(len(cor.index)): for j in range(len(cor.columns)): if cor.iloc[i,j] &gt;= 0.8 and i != j: drop_pairs."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://horizonnn.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">
      Bridge : you &amp; me
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/post/" title="Posts page">
              Posts
            </a>
          </li>
          
        </ul>
      
      











    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        POSTS
      </p>
      <h1 class="f1 athelas mb1">基本特征选择方法</h1>
      
      <time class="f6 mv4 dib tracked" datetime="2020-09-26T11:08:40&#43;08:00">September 26, 2020</time>
      
      
    </header>

    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>其中data为特征的DataFrame，y为目标值的Series，y_pre为预测值的Series</p>
<h1 id="filter">Filter</h1>
<h3 id="基于统计量的预处理">基于统计量的预处理</h3>
<ul>
<li>
<p>缺失值比例删除：删除高缺失值的特征（列）</p>
<pre><code>percent = data.isnull().sum() / len(data) * 100
result = data.loc[percent &lt; 50]
</code></pre></li>
<li>
<p>方差值删除：删除低方差的特征（列）</p>
<pre><code>var = data.var()
result = data.loc[var &gt; 0.1]
</code></pre></li>
<li>
<p>相关性矩阵：首先计算出特征之间的相关性，然后根据相关性的大小排序，按顺序删除冗余的特征</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 将数值范围变化到0-1之间</span>
data <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: (x <span style="color:#f92672">-</span> np<span style="color:#f92672">.</span>min(x)) <span style="color:#f92672">/</span> (np<span style="color:#f92672">.</span>max(x) <span style="color:#f92672">-</span> np<span style="color:#f92672">.</span>min(x)))
<span style="color:#75715e"># 相关性矩阵</span>
cor <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>corr()
<span style="color:#75715e"># 按相关性大小逐步剔除</span>
drop_pairs <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(cor<span style="color:#f92672">.</span>index)):
    <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(len(cor<span style="color:#f92672">.</span>columns)):
        <span style="color:#66d9ef">if</span> cor<span style="color:#f92672">.</span>iloc[i,j] <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0.8</span> <span style="color:#f92672">and</span> i <span style="color:#f92672">!=</span> j:
            drop_pairs<span style="color:#f92672">.</span>append([cor<span style="color:#f92672">.</span>index[i], cor<span style="color:#f92672">.</span>columns[j], cor<span style="color:#f92672">.</span>iloc[i,j]])
  
drop_pairs<span style="color:#f92672">.</span>sort(key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x:x[<span style="color:#ae81ff">2</span>], reverse<span style="color:#f92672">=</span>True)
  
data_corr_mean <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.6</span>
drop_cols <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> pair <span style="color:#f92672">in</span> drop_pairs:
    <span style="color:#66d9ef">if</span> pair[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">in</span> drop_cols <span style="color:#f92672">or</span> pair[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">in</span> drop_cols:
        <span style="color:#66d9ef">continue</span>
    <span style="color:#66d9ef">else</span>:
        drop_cols<span style="color:#f92672">.</span>append(pair[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">if</span> data_corr_mean[pair[<span style="color:#ae81ff">0</span>]] <span style="color:#f92672">&gt;</span> data_corr_mean[pair[<span style="color:#ae81ff">1</span>]] <span style="color:#66d9ef">else</span> pair[<span style="color:#ae81ff">1</span>])
indices <span style="color:#f92672">=</span> set([x <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> data<span style="color:#f92672">.</span>columns <span style="color:#66d9ef">if</span> x <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> drop_cols])
<span style="color:#66d9ef">return</span> data[indices]
</code></pre></div></li>
</ul>
<h3 id="基于统计量的排序">基于统计量的排序</h3>
<ul>
<li>分类问题：卡方检验、f_classif、mutual_info_classif、互信息</li>
<li>回归问题：皮尔森相关系数、f_regression、mutual_info_regression、最大信息系数</li>
</ul>
<h5 id="f-regression">f regression</h5>
<p>f regression的公式是$f = \frac{(x-\bar{x})(y-\bar{y})}{std(x)std(y)}$，其实就是在计算Pearson相关系数。但缺点在于只对线性关系敏感，对非线性关系并不敏感</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.feature_selection <span style="color:#f92672">import</span> SelectKBest
<span style="color:#f92672">from</span> sklearn.feature_selection <span style="color:#f92672">import</span> f_regression

<span style="color:#75715e"># 选取分数最高的10个特征</span>
selector <span style="color:#f92672">=</span> SelectKBest(f_regression, k<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)<span style="color:#f92672">.</span>fit(data, y)
indices <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>columns[selector<span style="color:#f92672">.</span>get_support()]
<span style="color:#66d9ef">return</span> data[indices]
</code></pre></div><h1 id="wrapper">Wrapper</h1>
<h3 id="正向特征消除">正向特征消除</h3>
<h3 id="反向特征消除">反向特征消除</h3>
<h3 id="递归特征消除rfe">递归特征消除（RFE）</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.feature_selection <span style="color:#f92672">import</span> RFE
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">RFE_select</span>(estimator, select_num, data, y)
    elselector <span style="color:#f92672">=</span> RFE(estimator, n_features_to_select<span style="color:#f92672">=</span>select_num)
    selector <span style="color:#f92672">=</span> sector<span style="color:#f92672">.</span>fit(data, y)
    indices <span style="color:#f92672">=</span> set(features<span style="color:#f92672">.</span>columns[selector<span style="color:#f92672">.</span>support_])
    <span style="color:#66d9ef">return</span> data[indices]
</code></pre></div><h1 id="embedded">Embedded</h1>
<h3 id="基于正则化的特征选择">基于正则化的特征选择</h3>
<h5 id="lassol1正则化">LASSO（L1正则化）</h5>
<h5 id="ridgel2正则化">Ridge（L2正则化）</h5>
<h3 id="随机稀疏模型">随机稀疏模型</h3>
<h3 id="基于树的特征选择">基于树的特征选择</h3>
<h5 id="随机森林">随机森林</h5>
<p>根据随机森林中得到的特征重要性进行排序得出特征的优先级</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> RandomForestRegressor

model <span style="color:#f92672">=</span> RandomForestRegressor()
model<span style="color:#f92672">.</span>fit(data, y)

<span style="color:#75715e"># 选取最重要的前10个特征</span>
indices <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argsort(model<span style="color:#f92672">.</span>feature_importances_)[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">10</span>]
<span style="color:#66d9ef">return</span> data[indices]
</code></pre></div><h1 id="特征提取">特征提取</h1>
<h3 id="因子分析fa">因子分析（FA）</h3>
<h3 id="独立分量分析ica">独立分量分析（ICA）</h3>
<h1 id="线性特征组合">线性特征组合</h1>
<h3 id="主成分分析pca">主成分分析（PCA）</h3>
<h1 id="非线性特征组合">非线性特征组合</h1>
<h3 id="isomap">ISOMAP</h3>
<h3 id="tsne">TSNE</h3>
<h3 id="umap">UMAP</h3>
<h3 id="heading"></h3>
<ul class="pa0">
  
</ul>
<div class="mt6">
      
      
      </div>
    </section>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://horizonnn.github.io/" >
    &copy; 2020 Bridge : you &amp; me
  </a>
    <div>










</div>
  </div>
</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
